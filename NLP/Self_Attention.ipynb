{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Reference:\n",
        "https://tiensu.github.io/blog/59_self-attention/\n",
        "(Phần tài liệu này nói theo buyơcs sẽ rất dễ hình dung)\n",
        "\n",
        "https://viblo.asia/p/kham-pha-suc-manh-cua-co-che-self-attention-trong-transformers-BQyJKj9R4Me\n",
        "(Đi sâu vào từng phần cũng như là khái niệm trong thuật toán)\n",
        "\n",
        "https://sebastianraschka.com/blog/2023/self-attention-from-scratch.html\n",
        "(Tài liệu tiếng anh đi sâu và chi tiết)\n"
      ],
      "metadata": {
        "id": "Ln4u93Tl2BGU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04l4JEqjWYeJ",
        "outputId": "15459c1a-8abc-45fa-c1e8-376f9c0b07ba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Life': 0, 'dessert': 1, 'eat': 2, 'first': 3, 'is': 4, 'short': 5}\n"
          ]
        }
      ],
      "source": [
        "sentence = 'Life is short, eat dessert first'\n",
        "\n",
        "dc = {s:i for i,s in enumerate(sorted(sentence.replace(',', '').split()))}\n",
        "print(dc)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "sentence_int = torch.tensor([dc[s] for s in sentence.replace(',', '').split()])\n",
        "print(sentence_int)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HpX2g4IQ8Di2",
        "outputId": "d013729e-d177-45b6-ae7a-661d99ffecab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 4, 5, 2, 1, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, using the integer-vector representation of the input sentence, we can use an embedding layer to encode the inputs into a real-vector embedding. Here, we will use a 16-dimensional embedding such that each input word is represented by a 16-dimensional vector. Since the sentence consists of 6 words, this will result in a 6×16-dimensional embedding"
      ],
      "metadata": {
        "id": "VY1KMlav8Y13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(123)\n",
        "embed = torch.nn.Embedding(6, 16)\n",
        "embedded_sentence = embed(sentence_int).detach()\n",
        "\n",
        "print(embedded_sentence)\n",
        "print(embedded_sentence.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGBaEeNL8dWA",
        "outputId": "7adc5a19-dd24-4efd-c6db-0a212ab125db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.3374, -0.1778, -0.3035, -0.5880,  0.3486,  0.6603, -0.2196, -0.3792,\n",
            "          0.7671, -1.1925,  0.6984, -1.4097,  0.1794,  1.8951,  0.4954,  0.2692],\n",
            "        [ 0.5146,  0.9938, -0.2587, -1.0826, -0.0444,  1.6236, -2.3229,  1.0878,\n",
            "          0.6716,  0.6933, -0.9487, -0.0765, -0.1526,  0.1167,  0.4403, -1.4465],\n",
            "        [ 0.2553, -0.5496,  1.0042,  0.8272, -0.3948,  0.4892, -0.2168, -1.7472,\n",
            "         -1.6025, -1.0764,  0.9031, -0.7218, -0.5951, -0.7112,  0.6230, -1.3729],\n",
            "        [-1.3250,  0.1784, -2.1338,  1.0524, -0.3885, -0.9343, -0.4991, -1.0867,\n",
            "          0.8805,  1.5542,  0.6266, -0.1755,  0.0983, -0.0935,  0.2662, -0.5850],\n",
            "        [-0.0770, -1.0205, -0.1690,  0.9178,  1.5810,  1.3010,  1.2753, -0.2010,\n",
            "          0.4965, -1.5723,  0.9666, -1.1481, -1.1589,  0.3255, -0.6315, -2.8400],\n",
            "        [ 0.8768,  1.6221, -1.4779,  1.1331, -1.2203,  1.3139,  1.0533,  0.1388,\n",
            "          2.2473, -0.8036, -0.2808,  0.7697, -0.6596, -0.7979,  0.1838,  0.2293]])\n",
            "torch.Size([6, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Defining the Weight Matrices"
      ],
      "metadata": {
        "id": "02YLJlYG9Ems"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Khởi tạo các tensor weights\n",
        "torch.manual_seed(123)\n",
        "\n",
        "d = embedded_sentence.shape[1]\n",
        "\n",
        "d_q, d_k, d_v = 24, 24, 28\n",
        "\n",
        "W_query = torch.nn.Parameter(torch.rand(d_q, d))\n",
        "W_key = torch.nn.Parameter(torch.rand(d_k, d))\n",
        "W_value = torch.nn.Parameter(torch.rand(d_v, d))\n",
        "\n",
        "print(d)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "59rsmUDz9EIl",
        "outputId": "426c985d-6224-48ab-afff-50e438717537"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(W_query)\n",
        "print(W_key)\n",
        "print(W_value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1VAEZLg-cWY",
        "outputId": "5b562ca9-bae0-4bef-f829-84086ad1bfdc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[0.2961, 0.5166, 0.2517, 0.6886, 0.0740, 0.8665, 0.1366, 0.1025, 0.1841,\n",
            "         0.7264, 0.3153, 0.6871, 0.0756, 0.1966, 0.3164, 0.4017],\n",
            "        [0.1186, 0.8274, 0.3821, 0.6605, 0.8536, 0.5932, 0.6367, 0.9826, 0.2745,\n",
            "         0.6584, 0.2775, 0.8573, 0.8993, 0.0390, 0.9268, 0.7388],\n",
            "        [0.7179, 0.7058, 0.9156, 0.4340, 0.0772, 0.3565, 0.1479, 0.5331, 0.4066,\n",
            "         0.2318, 0.4545, 0.9737, 0.4606, 0.5159, 0.4220, 0.5786],\n",
            "        [0.9455, 0.8057, 0.6775, 0.6087, 0.6179, 0.6932, 0.4354, 0.0353, 0.1908,\n",
            "         0.9268, 0.5299, 0.0950, 0.5789, 0.9131, 0.0275, 0.1634],\n",
            "        [0.3009, 0.5201, 0.3834, 0.4451, 0.0126, 0.7341, 0.9389, 0.8056, 0.1459,\n",
            "         0.0969, 0.7076, 0.5112, 0.7050, 0.0114, 0.4702, 0.8526],\n",
            "        [0.7320, 0.5183, 0.5983, 0.4527, 0.2251, 0.3111, 0.1955, 0.9153, 0.7751,\n",
            "         0.6749, 0.1166, 0.8858, 0.6568, 0.8459, 0.3033, 0.6060],\n",
            "        [0.9882, 0.8363, 0.9010, 0.3950, 0.8809, 0.1084, 0.5432, 0.2185, 0.3834,\n",
            "         0.3720, 0.5374, 0.9551, 0.7475, 0.4979, 0.8549, 0.2438],\n",
            "        [0.7577, 0.4536, 0.4130, 0.5585, 0.1170, 0.5578, 0.6681, 0.9275, 0.3443,\n",
            "         0.6800, 0.9998, 0.2855, 0.9753, 0.2518, 0.7204, 0.6959],\n",
            "        [0.6397, 0.8954, 0.2979, 0.6314, 0.5028, 0.1239, 0.3786, 0.1661, 0.7211,\n",
            "         0.5449, 0.5490, 0.3483, 0.5024, 0.3445, 0.6437, 0.9856],\n",
            "        [0.5757, 0.2785, 0.1946, 0.5382, 0.1291, 0.1242, 0.1746, 0.3302, 0.5370,\n",
            "         0.8443, 0.6937, 0.8831, 0.1861, 0.5422, 0.0556, 0.7868],\n",
            "        [0.6042, 0.9836, 0.1444, 0.9010, 0.9221, 0.9043, 0.5713, 0.9546, 0.8339,\n",
            "         0.8730, 0.4675, 0.1163, 0.4938, 0.5938, 0.1594, 0.2132],\n",
            "        [0.0206, 0.3247, 0.9355, 0.5855, 0.4695, 0.5201, 0.8118, 0.0585, 0.1142,\n",
            "         0.3338, 0.2122, 0.7579, 0.8533, 0.0149, 0.0757, 0.0131],\n",
            "        [0.6886, 0.9024, 0.1123, 0.2685, 0.6591, 0.1735, 0.9247, 0.6166, 0.3608,\n",
            "         0.5325, 0.6559, 0.3232, 0.1126, 0.5034, 0.5091, 0.5101],\n",
            "        [0.4270, 0.8210, 0.3605, 0.4516, 0.7056, 0.1853, 0.6339, 0.3894, 0.7398,\n",
            "         0.2288, 0.5185, 0.5489, 0.0977, 0.1364, 0.6918, 0.3545],\n",
            "        [0.7969, 0.0061, 0.2528, 0.0882, 0.6997, 0.4855, 0.4067, 0.4168, 0.1092,\n",
            "         0.6418, 0.5125, 0.1549, 0.6881, 0.4900, 0.0164, 0.7690],\n",
            "        [0.7674, 0.4058, 0.1548, 0.5201, 0.8773, 0.9577, 0.1226, 0.2742, 0.8893,\n",
            "         0.7444, 0.8095, 0.2511, 0.9308, 0.0890, 0.4759, 0.5104],\n",
            "        [0.5840, 0.1227, 0.9587, 0.9914, 0.1547, 0.5185, 0.2337, 0.9794, 0.7788,\n",
            "         0.7945, 0.6613, 0.4502, 0.7815, 0.5085, 0.3176, 0.7582],\n",
            "        [0.6569, 0.3704, 0.3630, 0.0578, 0.3629, 0.2974, 0.2275, 0.0484, 0.8916,\n",
            "         0.0532, 0.9964, 0.2377, 0.4616, 0.9079, 0.6650, 0.3573],\n",
            "        [0.0975, 0.2956, 0.9027, 0.3112, 0.9167, 0.4139, 0.4362, 0.6996, 0.4265,\n",
            "         0.4958, 0.8463, 0.6671, 0.4801, 0.6904, 0.9355, 0.6260],\n",
            "        [0.3534, 0.6638, 0.4563, 0.1091, 0.3069, 0.7274, 0.5164, 0.6845, 0.2073,\n",
            "         0.9727, 0.2913, 0.6066, 0.2557, 0.2588, 0.7239, 0.3604],\n",
            "        [0.1829, 0.2956, 0.8646, 0.8010, 0.8044, 0.0733, 0.7355, 0.6248, 0.1638,\n",
            "         0.5158, 0.6000, 0.2299, 0.2890, 0.9078, 0.4596, 0.4947],\n",
            "        [0.1836, 0.2010, 0.9603, 0.6861, 0.4209, 0.8046, 0.2621, 0.0638, 0.0036,\n",
            "         0.7032, 0.3051, 0.8070, 0.9271, 0.6647, 0.9296, 0.3848],\n",
            "        [0.9357, 0.2616, 0.4344, 0.8323, 0.2410, 0.8815, 0.6226, 0.4902, 0.9279,\n",
            "         0.8751, 0.2943, 0.5485, 0.5583, 0.9096, 0.7810, 0.9049],\n",
            "        [0.8048, 0.0649, 0.8322, 0.3672, 0.9012, 0.8146, 0.2077, 0.4474, 0.5746,\n",
            "         0.6429, 0.0369, 0.5224, 0.7605, 0.7823, 0.7459, 0.5791]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[0.0204, 0.8290, 0.1063, 0.2062, 0.5058, 0.6522, 0.7905, 0.4298, 0.2427,\n",
            "         0.4570, 0.6638, 0.2187, 0.0657, 0.7387, 0.1691, 0.2186],\n",
            "        [0.9148, 0.1705, 0.0943, 0.8800, 0.2614, 0.5325, 0.9981, 0.3005, 0.9657,\n",
            "         0.8973, 0.8862, 0.6483, 0.2746, 0.8148, 0.1575, 0.2087],\n",
            "        [0.2590, 0.7162, 0.5689, 0.8181, 0.8286, 0.5292, 0.7914, 0.1387, 0.0221,\n",
            "         0.0927, 0.7759, 0.9598, 0.3617, 0.7766, 0.1427, 0.4906],\n",
            "        [0.4970, 0.3552, 0.2576, 0.7346, 0.4564, 0.4009, 0.8474, 0.1203, 0.8265,\n",
            "         0.9441, 0.1928, 0.0263, 0.5696, 0.1197, 0.7091, 0.1012],\n",
            "        [0.1098, 0.6353, 0.3719, 0.0574, 0.6951, 0.6766, 0.5674, 0.8267, 0.2993,\n",
            "         0.9564, 0.1189, 0.9508, 0.8715, 0.0552, 0.4556, 0.2310],\n",
            "        [0.9920, 0.4791, 0.7945, 0.9323, 0.1144, 0.8039, 0.0651, 0.3650, 0.2984,\n",
            "         0.0324, 0.0290, 0.0179, 0.1132, 0.2206, 0.3352, 0.7797],\n",
            "        [0.4196, 0.0050, 0.1368, 0.8588, 0.0121, 0.2541, 0.0475, 0.7690, 0.8418,\n",
            "         0.5438, 0.2486, 0.3788, 0.5291, 0.7095, 0.5086, 0.2669],\n",
            "        [0.5242, 0.5153, 0.5047, 0.7175, 0.3116, 0.5315, 0.5021, 0.7111, 0.1939,\n",
            "         0.1091, 0.0931, 0.7101, 0.8978, 0.9959, 0.6785, 0.3981],\n",
            "        [0.5921, 0.0056, 0.5577, 0.3350, 0.4620, 0.7872, 0.3279, 0.1213, 0.5302,\n",
            "         0.3608, 0.2668, 0.3473, 0.2165, 0.9389, 0.5344, 0.2346],\n",
            "        [0.8188, 0.5773, 0.7870, 0.8855, 0.9941, 0.3705, 0.5148, 0.2103, 0.9562,\n",
            "         0.6591, 0.4172, 0.6253, 0.9961, 0.7036, 0.7429, 0.9616],\n",
            "        [0.5214, 0.5024, 0.6241, 0.0379, 0.6748, 0.4962, 0.4761, 0.5288, 0.9429,\n",
            "         0.6435, 0.0470, 0.9632, 0.8049, 0.7523, 0.7063, 0.5488],\n",
            "        [0.2239, 0.8205, 0.1264, 0.1976, 0.5013, 0.1121, 0.9536, 0.9967, 0.7492,\n",
            "         0.8052, 0.0157, 0.9315, 0.5878, 0.1842, 0.1508, 0.6205],\n",
            "        [0.8014, 0.3660, 0.3785, 0.4034, 0.0322, 0.8597, 0.4570, 0.0412, 0.1252,\n",
            "         0.6568, 0.0195, 0.8521, 0.0871, 0.4829, 0.6474, 0.2642],\n",
            "        [0.1753, 0.4471, 0.5900, 0.4111, 0.7243, 0.7618, 0.7006, 0.9619, 0.1965,\n",
            "         0.0994, 0.6232, 0.5908, 0.9808, 0.9848, 0.7145, 0.7961],\n",
            "        [0.7276, 0.4627, 0.0319, 0.3020, 0.0755, 0.8552, 0.2297, 0.1057, 0.4344,\n",
            "         0.8401, 0.7186, 0.6829, 0.4696, 0.0429, 0.2037, 0.0771],\n",
            "        [0.3508, 0.8447, 0.1685, 0.3713, 0.9908, 0.8435, 0.6818, 0.8176, 0.3984,\n",
            "         0.2316, 0.7526, 0.6348, 0.3449, 0.8858, 0.1437, 0.4895],\n",
            "        [0.9042, 0.6609, 0.1076, 0.5814, 0.4285, 0.7065, 0.7816, 0.1461, 0.3353,\n",
            "         0.9155, 0.1354, 0.3867, 0.3335, 0.3777, 0.4312, 0.7871],\n",
            "        [0.8124, 0.3208, 0.5582, 0.0361, 0.3112, 0.4533, 0.4819, 0.5912, 0.5274,\n",
            "         0.3513, 0.8600, 0.3362, 0.8992, 0.7952, 0.4890, 0.3156],\n",
            "        [0.8078, 0.5055, 0.2281, 0.7708, 0.5385, 0.9798, 0.0083, 0.6219, 0.0431,\n",
            "         0.2774, 0.4508, 0.9062, 0.2921, 0.2096, 0.4673, 0.4389],\n",
            "        [0.1036, 0.5142, 0.7655, 0.2849, 0.1029, 0.1462, 0.7376, 0.4695, 0.8627,\n",
            "         0.4548, 0.5098, 0.9156, 0.6635, 0.1461, 0.5924, 0.4857],\n",
            "        [0.1711, 0.9303, 0.7285, 0.2891, 0.0540, 0.7117, 0.0697, 0.6010, 0.1875,\n",
            "         0.5835, 0.5996, 0.7442, 0.3506, 0.4934, 0.2320, 0.5407],\n",
            "        [0.5300, 0.9356, 0.9819, 0.4110, 0.2879, 0.4350, 0.1694, 0.2705, 0.1740,\n",
            "         0.1762, 0.8907, 0.6352, 0.2929, 0.0072, 0.7181, 0.1904],\n",
            "        [0.0051, 0.0117, 0.6601, 0.6034, 0.5058, 0.0201, 0.6626, 0.0740, 0.5677,\n",
            "         0.5567, 0.1546, 0.4859, 0.1089, 0.9162, 0.3027, 0.7200],\n",
            "        [0.0670, 0.6579, 0.0233, 0.4404, 0.6203, 0.4648, 0.7944, 0.8952, 0.1405,\n",
            "         0.8582, 0.1465, 0.1765, 0.4007, 0.9541, 0.8567, 0.4604]],\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[2.2383e-01, 3.0465e-01, 3.0185e-01, 7.7719e-01, 4.9632e-01, 3.8457e-01,\n",
            "         9.4751e-02, 5.4099e-01, 8.0899e-01, 8.1570e-01, 5.4314e-01, 9.5954e-01,\n",
            "         3.7638e-01, 8.8847e-01, 7.7945e-01, 9.4166e-01],\n",
            "        [7.5758e-01, 4.9898e-02, 7.4476e-01, 1.3877e-01, 1.6512e-01, 1.4907e-01,\n",
            "         2.6847e-01, 5.0905e-02, 9.2707e-01, 2.8936e-01, 8.2721e-01, 9.4828e-01,\n",
            "         8.1707e-01, 8.7183e-01, 5.1264e-01, 8.6063e-03],\n",
            "        [8.0527e-01, 7.8735e-02, 6.2932e-01, 2.9138e-01, 8.2026e-01, 8.3362e-01,\n",
            "         4.7395e-01, 3.2585e-01, 8.8695e-01, 3.4264e-01, 1.1503e-01, 1.7675e-01,\n",
            "         2.1455e-02, 8.6990e-01, 8.7559e-01, 3.7270e-01],\n",
            "        [7.2059e-01, 7.8469e-01, 2.9878e-01, 5.8486e-01, 4.1490e-01, 2.5936e-01,\n",
            "         1.8493e-01, 2.5396e-01, 4.6260e-01, 4.3994e-01, 1.2095e-01, 4.5656e-02,\n",
            "         4.3196e-01, 6.9407e-01, 6.6612e-01, 1.4987e-01],\n",
            "        [7.6967e-01, 1.5432e-01, 2.5701e-01, 9.0780e-01, 6.2522e-01, 6.8266e-01,\n",
            "         1.8458e-02, 6.5164e-02, 4.0684e-01, 9.6096e-01, 6.7868e-03, 7.7611e-01,\n",
            "         2.6442e-01, 1.4285e-01, 8.8732e-01, 1.2021e-01],\n",
            "        [6.8133e-01, 3.7276e-01, 8.5715e-01, 2.5723e-02, 7.6188e-01, 8.0980e-01,\n",
            "         6.1699e-01, 9.3682e-01, 9.1631e-01, 7.7474e-01, 8.4722e-01, 9.2658e-01,\n",
            "         8.8112e-01, 7.4642e-01, 1.5909e-01, 7.7055e-01],\n",
            "        [4.8425e-01, 7.0663e-01, 4.9884e-01, 7.7782e-01, 5.1604e-02, 1.7298e-01,\n",
            "         3.3082e-01, 9.2754e-01, 1.7751e-01, 4.6892e-01, 3.3725e-01, 2.6404e-02,\n",
            "         5.3384e-02, 9.0279e-02, 7.4531e-02, 9.7112e-02],\n",
            "        [4.2062e-01, 9.6154e-01, 2.2990e-01, 3.2410e-01, 2.8857e-01, 6.1099e-01,\n",
            "         8.0211e-01, 2.7098e-01, 2.6750e-01, 6.6369e-01, 3.2836e-02, 7.9643e-01,\n",
            "         3.0695e-01, 7.2510e-01, 8.8686e-01, 6.1153e-01],\n",
            "        [1.2812e-02, 3.5339e-01, 9.2658e-01, 3.8711e-02, 9.1733e-01, 1.1971e-01,\n",
            "         3.9132e-01, 8.4936e-01, 2.8023e-02, 3.8628e-02, 3.9943e-01, 1.2943e-01,\n",
            "         4.5934e-01, 8.2646e-01, 7.5343e-01, 4.4913e-02],\n",
            "        [3.6892e-01, 1.2102e-01, 1.8199e-01, 7.3472e-01, 6.0274e-01, 9.7552e-01,\n",
            "         6.8528e-01, 1.4519e-01, 6.3655e-01, 1.6826e-01, 2.7941e-02, 7.4109e-02,\n",
            "         9.7227e-01, 2.5698e-01, 8.8271e-01, 1.6826e-01],\n",
            "        [9.5139e-01, 2.0317e-01, 6.4285e-01, 8.4507e-04, 2.9253e-01, 3.5884e-01,\n",
            "         4.6106e-01, 2.8258e-01, 3.8335e-01, 4.5231e-01, 8.4666e-01, 2.5868e-02,\n",
            "         1.2855e-01, 6.8069e-01, 4.2331e-01, 3.8708e-01],\n",
            "        [4.7674e-01, 9.5627e-01, 2.0533e-02, 8.6826e-01, 7.2311e-01, 2.0493e-01,\n",
            "         3.9773e-01, 3.5077e-01, 3.3057e-01, 1.9374e-01, 9.0709e-01, 9.7089e-01,\n",
            "         6.1383e-01, 7.6678e-01, 9.0303e-01, 7.4551e-01],\n",
            "        [9.9696e-01, 7.1538e-01, 3.1272e-03, 9.9986e-01, 5.4591e-01, 2.6334e-01,\n",
            "         5.9240e-01, 1.7805e-01, 2.8664e-01, 5.8276e-01, 3.4258e-01, 1.2603e-01,\n",
            "         4.7862e-01, 9.6871e-01, 4.9844e-01, 5.6016e-01],\n",
            "        [4.9144e-01, 1.9335e-01, 5.6547e-01, 1.3947e-01, 7.1792e-01, 9.7798e-01,\n",
            "         9.8303e-01, 3.8717e-01, 5.4474e-02, 5.8483e-01, 8.7221e-01, 5.9142e-01,\n",
            "         2.0964e-02, 9.8120e-01, 3.2919e-02, 6.0614e-01],\n",
            "        [9.7452e-01, 2.3828e-01, 3.8495e-01, 5.9646e-01, 3.6891e-01, 7.5607e-01,\n",
            "         6.2156e-01, 4.7269e-01, 4.8486e-01, 3.0533e-01, 4.2984e-01, 1.4502e-01,\n",
            "         9.9630e-01, 4.4357e-01, 6.6873e-01, 6.8975e-01],\n",
            "        [8.2953e-01, 3.5431e-01, 1.0604e-01, 4.3506e-01, 8.0488e-02, 3.4315e-01,\n",
            "         2.4547e-01, 3.7389e-03, 7.1329e-01, 9.9120e-01, 5.1161e-01, 8.9661e-01,\n",
            "         8.3075e-01, 9.1150e-01, 5.5886e-01, 8.2387e-01],\n",
            "        [1.2988e-01, 2.5011e-02, 6.6547e-01, 2.6829e-01, 9.9158e-01, 5.7032e-01,\n",
            "         3.3891e-01, 9.3563e-01, 9.7898e-01, 8.7122e-01, 8.0769e-01, 3.5685e-01,\n",
            "         7.7640e-01, 6.4864e-01, 3.1118e-01, 1.4588e-01],\n",
            "        [9.9964e-01, 5.9567e-02, 6.1331e-01, 2.5677e-01, 7.4479e-02, 2.6851e-01,\n",
            "         3.0593e-01, 7.8749e-01, 4.7445e-01, 9.6823e-01, 5.9971e-01, 5.0136e-01,\n",
            "         8.1705e-01, 4.3432e-01, 7.6012e-01, 6.5748e-01],\n",
            "        [4.8680e-01, 1.4728e-01, 8.6035e-01, 1.3611e-01, 6.9213e-01, 7.9141e-03,\n",
            "         5.5138e-01, 5.1960e-01, 6.9766e-01, 1.8325e-01, 8.8506e-02, 3.4613e-01,\n",
            "         2.5921e-01, 3.6149e-02, 8.6256e-01, 5.5304e-01],\n",
            "        [7.3236e-01, 7.4141e-01, 2.9814e-01, 3.2150e-01, 1.3247e-01, 9.1282e-01,\n",
            "         8.0841e-01, 3.9760e-01, 3.6337e-01, 9.1087e-01, 3.6575e-01, 3.2266e-01,\n",
            "         6.4184e-01, 3.1287e-01, 5.0166e-01, 8.7902e-01],\n",
            "        [1.2604e-01, 8.0083e-01, 2.1954e-01, 3.8633e-01, 7.4799e-01, 6.0365e-01,\n",
            "         8.1289e-01, 3.8198e-01, 8.9863e-01, 1.5036e-01, 6.4950e-01, 2.5026e-01,\n",
            "         2.9899e-01, 8.3617e-01, 1.2037e-02, 7.5694e-01],\n",
            "        [6.5635e-01, 3.5246e-01, 7.7813e-01, 8.9369e-01, 1.8693e-01, 8.2121e-01,\n",
            "         1.7736e-01, 2.4842e-01, 8.7530e-01, 8.0604e-01, 7.2358e-01, 4.3165e-02,\n",
            "         7.5033e-01, 6.8682e-01, 6.4769e-01, 7.5664e-01],\n",
            "        [7.4272e-01, 9.1680e-01, 5.7238e-01, 4.4882e-01, 5.7173e-01, 4.0714e-01,\n",
            "         8.9680e-01, 3.7979e-01, 1.9743e-01, 5.1343e-01, 3.0389e-01, 9.2211e-01,\n",
            "         9.6849e-01, 3.1945e-02, 7.6185e-01, 1.8171e-01],\n",
            "        [6.7478e-01, 7.9091e-02, 9.4587e-01, 8.1485e-02, 1.2109e-01, 8.0935e-01,\n",
            "         5.1930e-01, 4.0196e-01, 8.4459e-01, 2.8276e-01, 2.6690e-01, 3.8023e-01,\n",
            "         8.4015e-01, 8.6623e-02, 3.0478e-01, 2.3214e-01],\n",
            "        [9.2976e-01, 1.3616e-01, 7.5748e-01, 8.2101e-01, 2.2708e-01, 3.5492e-01,\n",
            "         8.1588e-01, 2.5691e-02, 6.7321e-01, 9.1517e-01, 1.8161e-01, 5.3942e-01,\n",
            "         6.8074e-01, 3.1517e-01, 9.3807e-01, 3.8948e-01],\n",
            "        [6.4266e-01, 7.2315e-01, 2.3211e-01, 3.4562e-01, 4.7240e-01, 9.3948e-01,\n",
            "         1.2437e-01, 7.5231e-01, 9.1875e-01, 6.0086e-01, 1.9832e-01, 8.0096e-01,\n",
            "         7.7884e-02, 6.4911e-01, 3.5634e-01, 4.1765e-01],\n",
            "        [1.1352e-01, 5.9395e-01, 1.9092e-01, 9.6893e-01, 5.8215e-01, 8.0316e-02,\n",
            "         2.3958e-01, 8.3629e-01, 8.2855e-01, 2.8586e-01, 6.4974e-01, 7.2764e-01,\n",
            "         5.0989e-02, 7.3622e-01, 1.7100e-01, 3.6668e-01],\n",
            "        [5.4811e-01, 8.1902e-01, 1.4077e-01, 8.3626e-01, 7.4442e-01, 9.7725e-01,\n",
            "         4.3640e-01, 4.7173e-01, 8.2328e-01, 3.9218e-02, 2.3207e-01, 3.2994e-01,\n",
            "         3.8522e-02, 2.7392e-01, 7.4236e-02, 3.4202e-02]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(W_query.shape)\n",
        "print(W_key.shape)\n",
        "print(W_value.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wGp3Cz2z-30u",
        "outputId": "ee0bac89-3345-4da6-e9b8-9c89ddcea153"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([24, 16])\n",
            "torch.Size([24, 16])\n",
            "torch.Size([28, 16])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5MA-Dk5Z-9FB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}