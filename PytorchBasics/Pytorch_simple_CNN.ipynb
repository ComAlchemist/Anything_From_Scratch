{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wpB6nNL-0lZS"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "A simple walkthrough of how to code a convolutional neural network (CNN)\n",
        "using the PyTorch library. For demonstration we train it on the very\n",
        "common MNIST dataset of handwritten digits. In this code we go through\n",
        "how to create the network as well as initialize a loss function, optimizer,\n",
        "check accuracy and more.\n",
        "\n",
        "Programmed by Aladdin Persson\n",
        "* 2020-04-08: Initial coding\n",
        "* 2021-03-24: More detailed comments and small revision of the code\n",
        "* 2022-12-19: Small revision of code, checked that it works with latest PyTorch version\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "# Imports\n",
        "import torch\n",
        "import torch.nn.functional as F  # Parameterless functions, like (some) activation functions\n",
        "import torchvision.datasets as datasets  # Standard datasets\n",
        "import torchvision.transforms as transforms  # Transformations we can perform on our dataset for augmentation\n",
        "from torch import optim  # For optimizers like SGD, Adam, etc.\n",
        "from torch import nn  # All neural network modules\n",
        "from torch.utils.data import (\n",
        "    DataLoader,\n",
        ")  # Gives easier dataset managment by creating mini batches etc.\n",
        "from tqdm import tqdm  # For nice progress bar!\n",
        "\n",
        "# Simple CNN\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self, in_channels=1, num_classes=10):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_channels=in_channels,\n",
        "            out_channels=8,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            padding=1,\n",
        "        )\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.conv2 = nn.Conv2d(\n",
        "            in_channels=8,\n",
        "            out_channels=16,\n",
        "            kernel_size=3,\n",
        "            stride=1,\n",
        "            padding=1,\n",
        "        )\n",
        "        self.fc1 = nn.Linear(16 * 7 * 7, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = self.pool(x)\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = self.pool(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Hyperparameters\n",
        "in_channels = 1\n",
        "num_classes = 10\n",
        "learning_rate = 3e-4 # karpathy's constant\n",
        "batch_size = 64\n",
        "num_epochs = 3\n",
        "\n",
        "# Load Data\n",
        "train_dataset = datasets.MNIST(\n",
        "    root=\"dataset/\", train=True, transform=transforms.ToTensor(), download=True\n",
        ")\n",
        "test_dataset = datasets.MNIST(\n",
        "    root=\"dataset/\", train=False, transform=transforms.ToTensor(), download=True\n",
        ")\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "# Initialize network\n",
        "model = CNN(in_channels=in_channels, num_classes=num_classes).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train Network\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_idx, (data, targets) in enumerate(tqdm(train_loader)):\n",
        "        # Get data to cuda if possible\n",
        "        data = data.to(device=device)\n",
        "        targets = targets.to(device=device)\n",
        "\n",
        "        # forward\n",
        "        scores = model(data)\n",
        "        loss = criterion(scores, targets)\n",
        "\n",
        "        # backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # gradient descent or adam step\n",
        "        optimizer.step()\n",
        "\n",
        "# Check accuracy on training & test to see how good our model\n",
        "def check_accuracy(loader, model):\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x = x.to(device=device)\n",
        "            y = y.to(device=device)\n",
        "\n",
        "            scores = model(x)\n",
        "            _, predictions = scores.max(1)\n",
        "            num_correct += (predictions == y).sum()\n",
        "            num_samples += predictions.size(0)\n",
        "\n",
        "    model.train()\n",
        "    return num_correct / num_samples\n",
        "\n",
        "\n",
        "print(f\"Accuracy on training set: {check_accuracy(train_loader, model)*100:.2f}\")\n",
        "print(f\"Accuracy on test set: {check_accuracy(test_loader, model)*100:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j57zdjsc0qIS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}